{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regressione lineare e polinomiale con scikit-learn\n",
    "\n",
    "**Programmazione di Applicazioni Data Intensive**  \n",
    "Laurea in Ingegneria e Scienze Informatiche  \n",
    "DISI - Università di Bologna, Cesena\n",
    "\n",
    "Proff. Gianluca Moro, Roberto Pasolini  \n",
    "`nome.cognome@unibo.it`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "Importare i package necessari per verificarne l'installazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ripasso: Regressione lineare\n",
    "\n",
    "Un _modello di regressione_ fornisce una stima $\\hat{y}$ del valore $y$ di una variabile _dipendente_ basata sui valori $x_1,\\ldots,x_n$ di una o più variabili _indipendenti_.\n",
    "\n",
    "In un modello di regressione _lineare_, il valore della variabile dipendente è previsto come combinazione lineare di quelli delle variabili indipendenti\n",
    "\n",
    "- ciascuna variabile indipendente $x_i$ è moltiplicata per un coefficiente $\\theta_i$\n",
    "- viene aggiunto un termine noto (_intercetta_) $\\theta_0$\n",
    "\n",
    "$$ \\hat{y} = \\theta_0+\\theta_1\\cdot x_1+\\ldots+\\theta_n\\cdot x_n $$\n",
    "\n",
    "Nella scorsa lezione, abbiamo visto come implementare la _discesa del gradiente_ per addestrare un modello di regressione lineare su dati esistenti\n",
    "\n",
    "Vediamo oggi come usare invece una libreria che fornisce questa funzione e altre più avanzate..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scikit-learn\n",
    "\n",
    "scikit-learn offre diversi algoritmi e funzioni di supporto per l'addestramento di modelli predittivi, dalla regressione lineare ad altri più avanzati\n",
    "\n",
    "- tutti i tipi di modelli offrono un'interfaccia comune per l'addestramento e la predizione (inferenza)\n",
    "- i dati in ingresso sono rappresentati come array NumPy o serie/frame pandas\n",
    "- sono fornite funzionalità di supporto (suddivisione dati, normalizzazione, ...) compatibili con tutti i tipi di modelli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Caso di studio 1: predizione consumo elettricità\n",
    "\n",
    "Carichiamo i dati già visti nel laboratorio precedente: per ogni giorno degli anni dal 2015 al 2017 abbiamo la temperatura media in una città e il picco registrato di consumo di corrente elettrica\n",
    "\n",
    "- con l'opzione `index_col` specifichiamo che la colonna `date` costituisce l'indice del DataFrame\n",
    "- con `parse_dates` indichiamo che i suoi valori vanno interpretati come date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POWER_DATA_URL = \"https://github.com/datascienceunibo/dialab2024/raw/main/Regressione_non_Lineare/power.csv\"\n",
    "\n",
    "import os.path\n",
    "if not os.path.exists(\"power.csv\"):\n",
    "    from urllib.request import urlretrieve\n",
    "    urlretrieve(POWER_DATA_URL, \"power.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = pd.read_csv(\"power.csv\", index_col=\"date\", parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "power.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Predizione nei mesi estivi\n",
    "\n",
    "Nella scorsa esercitazione, abbiamo estratto un modello di predizione sui consumi dei mesi estivi, imputabili all'aria condizionata\n",
    "\n",
    "Come la scorsa volta, selezioniamo dal frame caricato solamente le righe relative ai mesi di giugno, luglio e agosto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_summer = power.iloc[power.index.month.isin([6, 7, 8])]\n",
    "power_summer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addestramento di un modello\n",
    "\n",
    "Vediamo come addestrare un modello di regressione lineare su questi dati.\n",
    "\n",
    "Per prima cosa, va creato un oggetto che rappresenta il modello \"vuoto\", non ancora addestrato.\n",
    "\n",
    "A seconda del tipo di modello da addestrare, utilizziamo una classe diversa: per un modello di regressione lineare semplice (univariata o multivariata), creiamo un oggetto `LinearRegression`, importandolo dal package dei modelli lineari."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lrm = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usiamo quindi il metodo `fit` per addestrare il modello su un insieme di dati fornito.\n",
    "\n",
    "Al metodo `fit` vanno passati come argomenti:\n",
    "\n",
    "- una matrice (o DataFrame) di forma $m\\times n$, contenente $m$ osservazioni di $n$ variabili indipendenti $X_1,\\ldots,X_n$;\n",
    "- un vettore (o serie) di $m$ elementi, contenenti i corrispondenti valori noti della variabilie dipendente $Y$.\n",
    "\n",
    "Nel caso di regressione univariata con una variabile indipendente $X$, va passata una matrice $m\\times 1$ per esplicitare che si tratta di $m$ osservazioni di una variabile (piuttosto che di una osservazione di $n$ variabili).\n",
    "\n",
    "Selezionando la colonna `temp` come una lista (`[[\"temp\"]]` invece di `[\"temp\"]`), ottengo un DataFrame $m\\times 1$ invece di una semplice serie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = power_summer[[\"temp\"]]\n",
    "y = power_summer[\"demand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X` e `y` possono essere passate quindi come argomenti al metodo `fit`.\n",
    "\n",
    "Il metodo `fit` restituisce il modello stesso, che in versioni recenti di scikit-learn/Jupyter viene visualizzato in forma di diagramma (questo sarà utile per rappresentare modelli più complessi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`lrm` è ora un modello addestrato e può essere utilizzato per effettuare predizioni."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Inferenza\n",
    "\n",
    "Una volta che il modello è addestrato, possiamo ottenere predizioni col metodo `predict`:\n",
    "\n",
    "- va data in input una matrice o frame $m\\times n$ di osservazioni delle variabili indipendenti;\n",
    "- è restituito un vettore di $m$ valori della variabile dipendente previsti dal modello.\n",
    "\n",
    "Ad esempio, passiamo gli stessi dati usati per l'addestramento per vedere le predizioni del modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lrm.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo alcuni dei valori predetti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`predict` restituisce **sempre** un array NumPy. Per ottenere una serie pandas è necessario applicare manualmente le etichette, ad es. copiando quelle delle righe del frame dato in input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.Series( lrm.predict(X), index=power_summer.index )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Parametri del modello\n",
    "\n",
    "Una volta addestrato il modello possiamo consultarne i parametri tramite due attributi:\n",
    "\n",
    "- `coef_` restituisce un array dei coefficienti angolari (uno solo nel caso univariato);\n",
    "- `intercept_` restituisce il valore dell'intercetta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questi sono i valori di $\\alpha$ e $\\beta$ nella formula del modello lineare univariato $h(x)=\\alpha\\cdot x+\\beta$.\n",
    "\n",
    "Il metodo `predict` su una matrice `X` in pratica effettua il seguente calcolo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = X.values @ lrm.coef_ + lrm.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Misurare l'errore del modello\n",
    "\n",
    "Per misurare l'errore che un modello $h(\\mathbf{x})$ compie su un set di dati abbiamo usato nello scorso laboratorio l'_errore quadratico medio_ (_mean squared error_, MSE).\n",
    "\n",
    "$$ \\mathrm{MSE} = \\frac{1}{m}\\sum_{i=1}^n\\left(h(\\mathbf{x}_i)-y_i\\right)^2 $$\n",
    "\n",
    "Possiamo calcolarlo applicando la formula ai valori reali `y` e a quelli dati dal modello `preds`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.square(preds - y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In alternativa, possiamo usare l'apposita funzione `mean_squared_error` fornita da scikit-learn nel modulo `metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alla funzione vanno passati come argomenti:\n",
    "\n",
    "- il vettore (o serie) dei valori reali della variabile dipendente,\n",
    "- il vettore dei corrispondenti valori predetti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'errore è leggermente inferiore rispetto a quello ottenuto in precedenza con la discesa gradiente: questo perché scikit-learn calcola i parametri che minimizzano l'errore in modo analitico, per cui la soluzione sarà sempre migliore di (o uguale a) quella ottenuta con la discesa gradiente.\n",
    "\n",
    "La discesa gradiente torna però utile in problemi più complessi non risolvibili analiticamente, ad es. l'addestramento di reti neurali."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Errore relativo\n",
    "\n",
    "Il MSE è utilizzato per confrontare diversi modelli addestrati sugli stessi dati. Si usa in particolare in fase di addestramento, in quanto è facile estrarne la derivata.\n",
    "\n",
    "Esistono però altre metriche di errore, più facilmente interpretabili.\n",
    "\n",
    "L'_errore relativo_ misura intuitivamente di quanto il modello si sbaglia in percentuale rispetto al valore reale.\n",
    "\n",
    "$$ \\mathrm{errore} = \\frac{1}{m}\\sum_{i=1}^m\\left\\vert\\frac{h(\\mathbf{x}_i)-y_i}{y_i}\\right\\vert $$\n",
    "\n",
    "Come esempio su un singolo caso, se il valore reale da predire è 2 GW, ad una stima di 2,2 GW corrisponde un errore relativo del 10\\%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Definiamo una funzione per il calcolo, compatibile con quella usata sopra per il MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_error(y_true, y_pred):\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'errore relativo del modello sopra è:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_error(y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ovvero, le predizioni del modello hanno un errore medio del 5,68\\% rispetto al valore reale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Coefficiente di determinazione\n",
    "\n",
    "Il _coefficiente di determinazione_ $R^2$ è una misura che esprime intuitivamente quanto il modello catturi la variabilità presente nei dati ($\\bar{y}$ = media di $Y$).\n",
    "\n",
    "$$ R^2 = \\frac{\\sum_{i=1}^m{\\left(y_i-\\hat{y}_i\\right)^2}}{\\sum_{i=1}^m{\\left(y_i-\\bar{y}\\right)^2}} $$\n",
    "\n",
    "Il coefficiente $R^2$ è compreso tra 1 (il modello descrive perfettamente i dati) e 0 (nessuna relazione tra modello e dati).\n",
    "\n",
    "Questa metrica si può calcolare con la funzione `r2_score` del modulo `metrics` citato sopra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2_score(y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essendo la metrica di default per i modelli di regressione, si può anche usare il metodo `score` del modello passando le osservazioni delle variabili indipendenti e dipendente su cui calcolarla.\n",
    "\n",
    "Le predizioni non sono passate al metodo score perché sono calcolate usando `X`. `model.score(X, y)` equivale in pratica a `r2_score(y, model.predict(X))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Per comodità, creiamo una funzione che calcoli e stampi tutte e tre le metriche su dati e modello forniti.\n",
    "\n",
    "_(`{x:.5}` indica di stampare il valore `x` con 5 cifre decimali, con `%` lo si stampa in forma percentuale)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_eval(X, y, model):\n",
    "    preds = model.predict(X)\n",
    "    mse = mean_squared_error(y, preds)\n",
    "    re = relative_error(y, preds)\n",
    "    r2 = r2_score(y, preds)\n",
    "    print(f\"   Mean squared error: {mse:.5}\")\n",
    "    print(f\"       Relative error: {re:.5%}\")\n",
    "    print(f\"R-squared coefficient: {r2:.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testiamo la funzione sul modello sopra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval(power_summer[[\"temp\"]], power_summer[\"demand\"], lrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualizzazione del modello\n",
    "\n",
    "Definiamo una funzione che, dato un modello basato su una variabile indipendente, mostri la funzione descritta dal modello sovrapposta ai dati\n",
    "\n",
    "Si tratta della stessa funzione usata nella scorsa esercitazione, adattata per usare modelli di scikit-learn piuttosto che funzioni generiche.\n",
    "\n",
    "- Del modello passato viene invocato il metodo `predict`\n",
    "- La funzione `wrap_vector_in_frame` incapsula un vettore di valori di `x` in un DataFrame simile a quello dei dati originali (non è strettamente necessario, ma evita di visualizzare un warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_on_data(X, y, model=None):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(X, y)\n",
    "    if model is not None:\n",
    "        xlim, ylim = plt.xlim(), plt.ylim()\n",
    "        line_x = np.linspace(xlim[0], xlim[1], 100)\n",
    "        line_x_df = pd.DataFrame(line_x[:, None], columns=X.columns)\n",
    "        line_y = model.predict(line_x_df)\n",
    "        plt.plot(line_x, line_y, c=\"red\", lw=3)\n",
    "        plt.xlim(xlim); plt.ylim(ylim)\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"Temperatura (°C)\"); plt.ylabel(\"Consumi (GW)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Usiamo la funzione per visualizzare il modello sovrapposto ai dati su cui è stato addestrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_on_data(X, y, lrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il grafico mostra come il modello lineare sia efficace nell'approssimare la distribuzione dei dati."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iperparametri del modello\n",
    "\n",
    "Quando un modello di regressione viene addestrato, vengono individuati i valori ottimali dei suoi _parametri_: nel caso della regressione lineare, i parametri sono i _coefficienti angolari_ (uno solo nel caso univariato) e l'_intercetta_.\n",
    "\n",
    "Il processo di addestramento stesso può però avere a sua volta dei parametri che possono essere impostati, detti **_iperparametri_**. Ogni classe di modello di scikit-learn ha diversi iperparametri che possono essere impostati nel momento in cui si istanzia l'oggetto.\n",
    "\n",
    "Ad esempio `LinearRegression` ha per iperparametro `fit_intercept`, un flag che indica se calcolare un valore per l'intercetta:\n",
    "\n",
    "- se `True` (default), nell'addestramento si individua un valore ottimale per l'intercetta;\n",
    "- se `False`, il valore dell'intercetta viene fissato a 0 e vengono ottimizzati solo i coefficienti angolari.\n",
    "\n",
    "Addestriamo ad esempio un modello con `fit_intercept=False`, specificando tale opzione alla creazione dell'oggetto `LinearRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ni = null intercept\n",
    "lrm_ni = LinearRegression(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come sopra, utilizziamo il metodo `fit` per addestrare il modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm_ni.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stampando i parametri del modello vediamo che l'intercetta è 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm_ni.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm_ni.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcoliamo le misure di accuratezza viste sopra (MSE, errore relativo, R²) usando la funzione `print_eval` che abbiamo definito."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval(X, y, lrm_ni)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Il modello è leggermente meno accurato di quello con iperparametri default (`fit_intercept=True`), perché è stato rimosso un grado di libertà sull'addestramento\n",
    "- Creiamo un grafico personalizzato per confrontare i due modelli, si nota che il modello senza intercetta passa per (0, 0)\n",
    "  - usiamo la funzione `legend` di matplotlib per assegnare un'etichetta a ciascun elemento inserito nel grafico in ordine e visualizzare una legenda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(X, y)\n",
    "plt.scatter(0, 0, s=100, c=\"red\")\n",
    "line_x = np.linspace(-2, 32, 100)\n",
    "line_x_df = pd.DataFrame(line_x[:, None], columns=X.columns)\n",
    "line_y = lrm.predict(line_x_df)\n",
    "plt.plot(line_x, line_y, c=\"green\", lw=2)\n",
    "line_y0 = lrm_ni.predict(line_x_df)\n",
    "plt.plot(line_x, line_y0, c=\"red\", lw=2)\n",
    "plt.legend([\"Dati\", \"Origine\", \"Modello con intercetta\", \"Modello senza intercetta\"])\n",
    "plt.xlim((-2, 32))\n",
    "plt.ylim((-0.2, 2.8))\n",
    "plt.grid()\n",
    "plt.xlabel(\"Temperatura (°C)\")\n",
    "plt.ylabel(\"Consumi (GW)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Divisione tra training e test set\n",
    "\n",
    "Abbiamo visto come addestrare un modello di predizione su un set di dati e validarlo calcolandone diverse metriche **basandosi sugli stessi dati**.\n",
    "\n",
    "Per verificare se un modello generalizza correttamente i dati su cui è addestrato, è importante **validarlo su dati diversi**.\n",
    "\n",
    "Il metodo _hold-out_ prevede di dividere i dati a disposizione in\n",
    "\n",
    "- un _training set_ utilizzato solo per addestrare il modello,\n",
    "- un _test set_ (o _validation set_) utilizzato solo per calcolare le metriche di accuratezza del modello addestrato.\n",
    "\n",
    "La proporzione tra training e validation set è arbitraria, possono essere ad es. 50-50 e 66-33."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Avendo dati in ordine cronologico, è comune utilizzare quelli meno recenti come training set e quelli più recenti come test set.\n",
    "\n",
    "In questo caso scegliamo di utilizzare i dati del 2015 come training set e quelli del 2016 e 2017 come test set.\n",
    "\n",
    "Definiamo un array booleano che indichi quali dati fanno parte del training set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train = power_summer.index.year < 2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo usiamo quindi per selezionare i dati del training e del test set (l'operatore `~` esegue il NOT elemento per elemento)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summer_train = power_summer.loc[is_train]\n",
    "summer_test = power_summer.loc[~is_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 1: Addestramento e validazione modello\n",
    "\n",
    "- **(1a)** Estrarre esplicitamente il DataFrame della variabile indipendente (`temp`) e la serie della variabile dipendente (`demand`) dai due DataFrame `summer_train` e `summer_val`\n",
    "- **(1b)** Creare ed addestrare un modello di regressione lineare sul training set `summer_train`\n",
    "- **(1c)** Stampare le metriche di valutazione viste (MSE, errore relativo, R²) calcolate sullo stesso training set\n",
    "- **(1d)** Stampare le stesse metriche calcolate sul test set `summer_test`\n",
    "- **(1e)** Mostrare il grafico del modello sovrapposto al training set\n",
    "- **(1f)** Mostrare il grafico del modello sovrapposto al test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1a\n",
    "summer_X_train = summer_train[[\"temp\"]]\n",
    "summer_y_train = summer_train[\"demand\"]\n",
    "summer_X_test = summer_test[[\"temp\"]]\n",
    "summer_y_test = summer_test[\"demand\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1b\n",
    "summer_lrm = LinearRegression()\n",
    "summer_lrm.fit(summer_X_train, summer_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1c\n",
    "print(\"Training set:\")\n",
    "print_eval(summer_X_train, summer_y_train, summer_lrm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1d\n",
    "print(\"Training set:\")\n",
    "print_eval(summer_X_test, summer_y_test, summer_lrm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1e Mostrare il grafico del modello sovrapposto al training set\n",
    "plot_model_on_data(summer_X_train, summer_y_train, summer_lrm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1f\n",
    "plot_model_on_data(summer_X_test, summer_y_test, summer_lrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Caso di studio 2: predizione dei prezzi delle case\n",
    "\n",
    "Riprendiamo dalla scorsa esercitazione il dataset relativo ai prezzi delle case. Sono fornite informazioni (tasso criminalità, inquinamento, demografia, ...) su diversi quartieri: in base a queste va stimato per ciascuno il prezzo mediano delle abitazioni (`MEDV`).\n",
    "\n",
    "Contrariamente all'altra volta, forniamo tale dataset già adattato per essere caricato con `read_csv` senza impostare opzioni aggiuntive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOUSING_DATA_URL = \"https://github.com/datascienceunibo/dialab2024/raw/main/Regressione_non_Lineare/housing.csv\"\n",
    "\n",
    "import os.path\n",
    "if not os.path.exists(\"housing.csv\"):\n",
    "    from urllib.request import urlretrieve\n",
    "    urlretrieve(HOUSING_DATA_URL, \"housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv(\"housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "housing.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Divisione training-test con scikit-learn\n",
    "\n",
    "Abbiamo visto il metodo _hold-out_ in cui i dati disponibili sono divisi in training e test set.\n",
    "\n",
    "scikit-learn fornisce un'apposita funzione `train_test_split` per suddividere casualmente un set di dati in due insiemi \"train\" e \"test\" disgiunti.\n",
    "\n",
    "- il set di dati è una sequenza di elementi, es. array NumPy o serie/frame pandas\n",
    "- con l'opzione `test_size=X` si indica la proporzione (se X decimale tra 0 e 1) o il numero di elementi (se X intero) da inserire nel test set (default 0.25, ovvero 25\\%)\n",
    "- tutti i dati non selezionati per il test set sono implicitamente selezionati per il training set\n",
    "- con l'opzione `random_state` si indica un seed per la riproducibilità: richiamando la funzione più volte con `random_state` e altri parametri uguali viene riprodotta esattamente la stessa suddivisione\n",
    "\n",
    "Ad esempio, dividiamo il frame `housing` in due parti casuali `train_data` e `test_data`, contenenti rispettivamente 2/3 e 1/3 dei dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_data, test_data = train_test_split(housing, test_size=1/3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "I due nuovi frame contengono due sottoinsiemi disgiunti delle righe di `housing`, mescolate casualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A `train_test_split` possiamo passare **due (o più) collezioni** con pari numero di elementi per far sì che siano suddivise insieme, applicando **a tutte lo stesso ordine** casuale dei dati\n",
    "\n",
    "Ad esempio separiamo `housing` in due strutture dati allineate:\n",
    "\n",
    "- una serie `y` con i valori della variabile dipendente (`MEDV`),\n",
    "- un frame `X` con i valori delle variabili indipendenti (tutte le altre)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = housing[\"MEDV\"]\n",
    "X = housing.drop(columns=[\"MEDV\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applichiamo quindi `train_test_split` congiuntamente a `X` e `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=1/3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Si può verificare dagli indici che l'ordine delle righe di `X_train` è lo stesso di `y_train` (lo stesso vale per `X_test` e `y_test`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(X_train.index, y_train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esercizio 2: Regressione su prezzi case\n",
    "\n",
    "- **(2a)** Creare ed addestrare un modello di regressione lineare sul training set dei prezzi delle case creato sopra composto da `X_train` e `y_train`\n",
    "- **(2b)** Stampare le metriche di valutazione viste (MSE, errore relativo, R²) calcolate sullo stesso set\n",
    "- **(2c)** Stampare le stesse metriche calcolate sul validation set composto da `X_test` e `y_test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2a\n",
    "lrm = LinearRegression()\n",
    "lrm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2b\n",
    "print_eval(X_train, y_train, lrm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2c\n",
    "print_eval(X_test, y_test, lrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predizione consumi elettrici sull'intero anno\n",
    "\n",
    "Riprendiamo il caso di studio sulla predizione dei consumi elettrici dalla temperatura.\n",
    "\n",
    "I modelli addestrati sopra sono addestrati e validati solamente sui mesi estivi.\n",
    "\n",
    "È possibile addestrare un modello utilizzabile per la predizione sull'intero anno?\n",
    "\n",
    "Iniziamo dividendo l'intero frame `data` in training e test set ed estraiamo per ciascuno la matrice `X` e il vettore `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train = power.index.year < 2016\n",
    "X_train = power.loc[is_train, [\"temp\"]]\n",
    "y_train = power.loc[is_train, \"demand\"]\n",
    "X_test = power.loc[~is_train, [\"temp\"]]\n",
    "y_test = power.loc[~is_train, \"demand\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addestriamo un nuovo modello sul training set estratto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrm = LinearRegression()\n",
    "lrm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Validiamo il modello sia sullo stesso training set che sul validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval(X_train, y_train, lrm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval(X_test, y_test, lrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In entrambi i casi, il modello è poco accurato: lo si deduce in particolare dal coefficiente R² vicino allo zero.\n",
    "\n",
    "Visualizziamo il modello sovrapposto ai dati (training e test insieme) per indagare..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "plot_model_on_data(power[[\"temp\"]], power[\"demand\"], lrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il grafico evidenzia che l'aumento dei consumi si ha sia nelle giornate più calde (a destra) che in quelle più fredde (a sinistra).\n",
    "\n",
    "Per questo il consumo non può essere approssimato dalla temperatura in modo soddisfacente con un unico modello lineare (una retta) per tutti i mesi dell'anno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regressione polinomiale\n",
    "\n",
    "La regressione _polinomiale_ è una generalizzazione di quella lineare in cui il modello include **termini di grado superiore**.\n",
    "\n",
    "Ad esempio, mentre un modello di regressione lineare su una singola variabile $x$ (_univariata_) ha forma\n",
    "\n",
    "$$ \\hat{y}=\\theta_0+\\theta_1\\cdot x $$\n",
    "\n",
    "in un modello polinomiale di secondo grado viene aggiunto un termine col quadrato della variabile, con un proprio coefficiente:\n",
    "\n",
    "$$ \\hat{y}=\\theta_0+\\theta_1\\cdot x+\\theta_2\\cdot x^2 $$\n",
    "\n",
    "Analogamente, in un modello di terzo grado viene aggiunto un ulteriore termine col cubo della variabile:\n",
    "\n",
    "$$ \\hat{y}=\\theta_0+\\theta_1\\cdot x+\\theta_2\\cdot x^2+\\theta_3\\cdot x^3 $$\n",
    "\n",
    "La regressione polinomiale corrisponde in pratica a quella lineare con l'aggiunta di variabili derivate da quelle esistenti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Addestriamo ad esempio un modello polinomiale di secondo grado.\n",
    "\n",
    "Creiamo una matrice `X_train_sq` con i quadrati elemento per elemento di `X_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sq = X_train ** 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usiamo quindi `np.c_` per unire le due matrici $m\\times 1$ in una $m\\times 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_d2 = np.c_[X_train, X_train_sq]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo quindi un dataset con due variabili, dove la seconda è il quadrato della prima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_d2[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Creiamo come al solito un modello di regressione lineare e addestriamolo con questi dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prm = LinearRegression()\n",
    "prm.fit(X_train_d2, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo già valutare il modello sul training set stesso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval(X_train_d2, y_train, prm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Per valutarlo sul test set, ricaviamo da esso (`X_test`) una matrice `X_test_d2` che includa il quadrato di `X` come fatto prima per il training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_d2 = np.c_[X_test, X_test ** 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval(X_test_d2, y_test, prm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo che questo modello con l'aggiunta del termine di secondo grado è molto più accurato di quello lineare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 3: Regressione polinomiale di terzo grado\n",
    "\n",
    "- **(3a)** Creare una matrice `X_train_d3` con tre colonne contenenti rispettivamente i valori di `X_train`, i quadrati e i cubi\n",
    "- **(3b)** Creare una matrice analoga `X_test_d3` basata su `X_test`\n",
    "- **(3c)** Addestrare un modello di regressione lineare su `X_train_d3`\n",
    "- **(3d)** Stampare le metriche di valutazione del modello su `X_train_d3` e `X_test_d3`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3a\n",
    "X_train_d3 = np.c_[X_train, X_train ** 2, X_train ** 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3b\n",
    "X_test_d3 = np.c_[X_test, X_test ** 2, X_test ** 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3c\n",
    "prm = LinearRegression()\n",
    "prm.fit(X_train_d3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3d\n",
    "print_eval(X_train_d3, y_train, prm)\n",
    "print_eval(X_test_d3, y_test, prm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature polinomiali con scikit-learn\n",
    "\n",
    "Per applicare trasformazioni ai dati da fornire ai modelli, scikit-learn fornisce dei _filtri_ con un'interfaccia standard.\n",
    "\n",
    "Ad esempio, per generare le variabili per la regressione polinomiale, possiamo usare l'apposito filtro `PolynomialFeatures`.\n",
    "\n",
    "In modo simile ai modelli di predizione, un filtro va dapprima creato, impostandone eventuali iperparametri.\n",
    "\n",
    "L'iperparametro principale di `PolynomialFeatures` è `degree`, che indica il grado massimo delle feature da generare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come i modelli (es. `LinearRegression`), i filtri vanno \"addestrati\" con dei dati d'esempio prima di essere utilizzati. Nel caso di `PolynomialFeatures` l'addestramento serve solo a indicare quali variabili sono presenti nei dati in input.\n",
    "\n",
    "Ad esempio, creiamo una matrice con due osservazioni (righe) di una generica variabile (colonna) $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.array([ [ 2],\n",
    "                    [-3] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passiamo ora questa matrice al metodo `fit`: il filtro apprende che i dati sono composti da una singola variabile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.fit(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una volta addestrato, possiamo usare il metodo `transform` del filtro per trasformare qualsiasi matrice compatibile, ovvero con una sola colonna.\n",
    "\n",
    "Trasformiamo ad esempio la stessa matrice usata in `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.transform(sample)\n",
    "#        X^0   X^1   X^2   X^3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dati i valori di $X$, il filtro ha restituito i valori di $X^0, X^1, X^2, X^3$.\n",
    "\n",
    "I filtri forniscono un metodo `fit_transform` che raggruppa le due operazioni sopra: addestra il modello sui dati passati (`fit`) e li trasforma (`transform`).\n",
    "\n",
    "In pratica `fit_transform` va invocato al primo utilizzo di un filtro, mentre per i successivi utilizzi va invocato `transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=3)\n",
    "poly.fit_transform(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La colonna $X^0$ ha sempre valore 1 ed è inutile nell'addestrare il modello, in quanto sarebbe ridondante con l'intercetta.\n",
    "\n",
    "Possiamo escluderla impostando l'iperparametro `include_bias=False` sul filtro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "poly.fit_transform(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Per addestrare un modello polinomiale possiamo quindi creare il filtro per l'aggiunta delle feature, ad esempio di secondo grado..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...e addestrare un modello lineare con i dati trasformati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prm = LinearRegression()\n",
    "X_train_sq = poly.fit_transform(X_train)\n",
    "prm.fit(X_train_sq, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In seguito, i valori della _x_ dovranno sempre essere trasformati con lo stesso filtro, utilizzando il metodo `transform`.\n",
    "\n",
    "Ad esempio, per ottenere i consumi predetti a fronte di temperature di -5 °C, 5 °C e 25 °C..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = [ [-5], [5], [25] ]\n",
    "sample_sq = poly.transform(sample)\n",
    "prm.predict(sample_sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per ottenere invece le metriche d'accuratezza..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sq = poly.transform(X_test)\n",
    "print_eval(X_test_sq, y_test, prm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipeline\n",
    "\n",
    "Ad ogni interazione col modello `prm` sopra dobbiamo esplicitamente trasformare i dati in ingresso col filtro `poly`: questo rende l'utilizzo del modello più scomodo ed incline ad errori.\n",
    "\n",
    "Per questi casi, scikit-learn permette di integrare uno o più filtri ed un modello di predizione in un unico blocco, detto **_pipeline_**.\n",
    "\n",
    "Una volta costruita, la pipeline offre la **stessa API del modello** di predizione incapsulato, ma **applica automaticamente i filtri** ai dati prima di passarli al modello:\n",
    "\n",
    "- chiamando `fit`, i filtri sono addestrati e applicati (`fit_transform`) sui dati di addestramento;\n",
    "- chiamando `predict` (o `score`), i filtri già tarati sono applicati ai nuovi dati (`transform`).\n",
    "\n",
    "Ad esempio, per creare un modello polinomiale facile da usare, incapsuliamo in una pipeline un filtro `PolynomialFeatures` e un modello `LinearRegression`.\n",
    "\n",
    "Usiamo la classe `Pipeline`, passando al costruttore la lista dei componenti **in ordine di applicazione**. Ciascun componente è rappresentato da una tupla con un nome e la definizione del componente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "prm = Pipeline([\n",
    "    # nome     elemento\n",
    "    (\"poly\",   PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    (\"linreg\", LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Possiamo ora eseguire le stesse operazioni vista sopra sul modello, ma con la trasformazione dei dati applicata in automatico. Nella rappresentazione grafica del modello è possibile vedere i due componenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# addestramento\n",
    "prm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inferenza\n",
    "prm.predict([ [-5], [5], [25] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcolo accuratezza\n",
    "print_eval(X_test, y_test, prm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Tramite l'attributo `named_steps` della pipeline possiamo accedere ai singoli componenti: funziona come un dizionario le cui chiavi sono i nomi assegnati ai componenti nel costruttore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prm.named_steps.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo ad esempio reperire il modello di regressione lineare `linreg`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prm.named_steps[\"linreg\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...e vedere i pesi assegnati alle due variabili, nell'ordine X e X²."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prm.named_steps[\"linreg\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Curva del modello polinomiale\n",
    "\n",
    "Visualizzando il modello polinomiale di secondo grado in un grafico, vediamo che ha la forma di una funzione $a\\cdot x^2+b\\cdot x+c$, ovvero una parabola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_on_data(X_test, y_test, prm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come anche confermato dalle misure di errore, questo modello approssima molto meglio il consumo in base alla temperatura rispetto a quello lineare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 4: Regressione polinomiale con pipeline\n",
    "\n",
    "- **(4a)** Creare un modello di regressione polinomiale di terzo grado usando una pipeline come sopra\n",
    "- **(4b)** Addestrare il modello sui dati di training\n",
    "- **(4c)** Stampare le misure di accuratezza del modello calcolate sui dati di training e su quelli di test\n",
    "- **(4d)** Visualizzare il grafico del modello sovrapposto ai dati di test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4a\n",
    "prm = Pipeline([\n",
    "    # nome     elemento\n",
    "    (\"poly\",   PolynomialFeatures(degree=3, include_bias=False)),\n",
    "    (\"linreg\", LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4b\n",
    "prm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4c\n",
    "print_eval(X_train, y_train, prm)\n",
    "print_eval(X_test, y_test, prm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4d\n",
    "plot_model_on_data(X_test, y_test, prm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Standardizzazione dei dati\n",
    "\n",
    "Data una variabile $X$ con media $\\mu$ e deviazione standard $\\sigma$, la sua versione \"standard\" è calcolata come\n",
    "\n",
    "$$ Z = \\frac{X-\\mu}{\\sigma} $$\n",
    "\n",
    "$Z$ mantiene la distribuzione dei dati di $X$, ma con media 0 e deviazione standard 1.\n",
    "\n",
    "In presenza di più variabili con scale diverse, applicare la standardizzazione a ciascuna di esse è utile per uniformarne i valori: questo può migliorare l'accuratezza dei modelli di regressione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La standardizzazione si esegue col filtro `StandardScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Eseguendo `fit_transform` (o `fit`) il filtro memorizza medie e deviazioni standard dei dati passati, salvate negli attributi `mean_` e `scale_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit_transform([[0.001, 4000],\n",
    "                      [0.002, 2500],\n",
    "                      [0.004, 1000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.scale_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Successivamente `transform` trasformerà ulteriori dati secondo medie e deviazioni memorizzate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.transform([ [0.01, 100] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Addestriamo un modello polinomiale di secondo grado come quello sopra, ma applicando la standardizzazione alle variabili $X$ e $X^2$.\n",
    "\n",
    "Per far ciò, basta aggiungere il filtro alla pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prm = Pipeline([\n",
    "    (\"poly\",   PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    (\"scale\",  StandardScaler()),   # <- aggiunto\n",
    "    (\"linreg\", LinearRegression())\n",
    "])\n",
    "prm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Valutiamo l'accuratezza del modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval(X_test, y_test, prm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo caso le metriche di accuratezza non sono cambiate standardizzando i dati.\n",
    "\n",
    "Ma cosa succede con più variabili con ordini di grandezza molto diversi?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizzazione min-max dei dati\n",
    "\n",
    "Una tecnica alternativa alla standardizzazione per preprocessare dati in scale diverse è la _normalizzazione minimo-massimo_, che porta i valori di ogni variabile in un intervallo prestabilito, di solito tra 0 e 1.\n",
    "\n",
    "Data una generica variabile $X$, la sua normalizzazione $N$ si calcola come\n",
    "\n",
    "$$ N=\\frac{X-\\min(X)}{\\max(X)-\\min(X)}$$\n",
    "\n",
    "Tale trasformazione si effettua col filtro `MinMaxScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addestrando il filtro, vengono salvati gli attributi `min_` ($\\min(X)$) e `scale_` ($\\frac{1}{\\max(X)-\\min(X)}$) usati per effettuare la normalizzazione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit_transform([[0.001, 4000],\n",
    "                      [0.002, 2500],\n",
    "                      [0.004, 1000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.scale_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Esercizio 5: Normalizzazione\n",
    "\n",
    "- **(5a)** Addestrare sul training set un modello di regressione polinomiale di grado 15 (con variabili $X,X^2,\\ldots,X^{15}$) e verificarne le misure di accuratezza sul test set\n",
    "- **(5b)** Ripetere il punto 4a, ma applicando la standardizzazione dei dati nel modello\n",
    "- **(5c)** Ripetere il punto 4a, ma applicando la normalizzazione min-max dei dati nel modello\n",
    "\n",
    "Avendo a che fare con molte variabili di ordini di grandezza diversi, la standardizzazione contribuisce a migliorare l'accuratezza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5a\n",
    "prm = Pipeline([\n",
    "    (\"poly\",   PolynomialFeatures(degree=15, include_bias=False)),\n",
    "    (\"linreg\", LinearRegression())\n",
    "])\n",
    "prm.fit(X_train, y_train)\n",
    "print_eval(X_test, y_test, prm)\n",
    "plot_model_on_data(X_test, y_test, prm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5b\n",
    "prm = Pipeline([\n",
    "    (\"poly\",   PolynomialFeatures(degree=15, include_bias=False)),\n",
    "    (\"scale\",  StandardScaler()), \n",
    "    (\"linreg\", LinearRegression())\n",
    "])\n",
    "prm.fit(X_train, y_train)\n",
    "print_eval(X_test, y_test, prm)\n",
    "plot_model_on_data(X_test, y_test, prm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5c\n",
    "prm = Pipeline([\n",
    "    (\"poly\",   PolynomialFeatures(degree=15, include_bias=False)),\n",
    "    (\"scale\",  MinMaxScaler()), \n",
    "    (\"linreg\", LinearRegression())\n",
    "])\n",
    "prm.fit(X_train, y_train)\n",
    "print_eval(X_test, y_test, prm)\n",
    "plot_model_on_data(X_test, y_test, prm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
