{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regressione con regolarizzazione, funzioni kernel, cross validation, grid search\n",
    "\n",
    "**Programmazione di Applicazioni Data Intensive**  \n",
    "Laurea in Ingegneria e Scienze Informatiche  \n",
    "DISI - Università di Bologna, Cesena\n",
    "\n",
    "Proff. Gianluca Moro, Roberto Pasolini  \n",
    "`nome.cognome@unibo.it`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "Importare i package necessari e configurare l'output di matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Caso di studio: predizione consumo elettricità\n",
    "\n",
    "Carichiamo i dati già visti nei laboratori precedenti: per ogni giorno degli anni dal 2015 al 2017 abbiamo la temperatura media in una città e il picco registrato di consumo di corrente elettrica\n",
    "\n",
    "- con l'opzione `index_col` specifichiamo che la colonna `date` costituisce l'indice del DataFrame\n",
    "- con `parse_dates` indichiamo che i suoi valori vanno interpretati come date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POWER_DATA_URL = \"https://github.com/datascienceunibo/dialab2024/raw/main/Regressione_non_Lineare/power.csv\"\n",
    "\n",
    "import os.path\n",
    "if not os.path.exists(\"power.csv\"):\n",
    "    from urllib.request import urlretrieve\n",
    "    urlretrieve(POWER_DATA_URL, \"power.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power = pd.read_csv(\"power.csv\", index_col=\"date\", parse_dates=[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "power.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vogliamo costruire un modello che consenta la predizione del consumo di corrente sulla base della temperatura in un qualsiasi giorno dell'anno\n",
    "\n",
    "Come nello scorso laboratorio, suddividiamo i dati in\n",
    "\n",
    "- un _training set_ `*_train` con i dati relativi all'anno 2015\n",
    "- un _test set_ `*_test` con i dati relativi agli anni 2016 e 2017\n",
    "\n",
    "Per ciascuno estraiamo\n",
    "\n",
    "- una matrice `X_*` $N\\times 1$ con le osservazioni delle variabili indipendenti: in questo caso una sola, la temperatura\n",
    "- un vettore `y_*` con gli $N$ corrispondenti valori della variabile dipendente: i consumi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train = power.index.year < 2016\n",
    "X_train = power.loc[is_train, [\"temp\"]]\n",
    "y_train = power.loc[is_train, \"demand\"]\n",
    "X_test = power.loc[~is_train, [\"temp\"]]\n",
    "y_test = power.loc[~is_train, \"demand\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valutazione dei modelli\n",
    "\n",
    "Abbiamo visto tre diverse metriche per la valutazione dell'accuratezza dei modelli di regressione\n",
    "\n",
    "- l'_errore quadratico medio_, usato nella discesa del gradiente ma più difficilmente interpretabile\n",
    "- l'_errore relativo_, noto in letteratura come _mean absoulte percentage error_ (MAPE), che indica intuitivamente la percentuale di errore del modello\n",
    "- il _coefficiente R²_, che esprime l'accuratezza con un indice tra 0 e 1\n",
    "\n",
    "Riprendiamo la funzione `print_eval` definita nella scorsa esercitazione per calcolare e stampare le tre metriche su un set di dati e un modello indicati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "def print_eval(X, y, model):\n",
    "    preds = model.predict(X)\n",
    "    mse = mean_squared_error(y, preds)\n",
    "    re = mean_absolute_percentage_error(y, preds)\n",
    "    r2 = r2_score(y, preds)\n",
    "    print(f\"   Mean squared error: {mse:.5}\")\n",
    "    print(f\"       Relative error: {re:.5%}\")\n",
    "    print(f\"R-squared coefficient: {r2:.5}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Riprendiamo anche la funzione `plot_model_on_data` per visualizzare un grafico del modello addestrato sovrapposto ai dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_on_data(X, y, model=None):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(X, y)\n",
    "    if model is not None:\n",
    "        xlim, ylim = plt.xlim(), plt.ylim()\n",
    "        line_x = np.linspace(xlim[0], xlim[1], 100)\n",
    "        line_x_df = pd.DataFrame(line_x[:, None], columns=X.columns)\n",
    "        line_y = model.predict(line_x_df)\n",
    "        plt.plot(line_x, line_y, c=\"red\", lw=3)\n",
    "        plt.xlim(xlim); plt.ylim(ylim)\n",
    "    plt.grid()\n",
    "    plt.xlabel(\"Temperatura (°C)\"); plt.ylabel(\"Consumi (GW)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Esercizio 1: Ripasso modelli\n",
    "\n",
    "Addestrare sul training set creato sopra tre modelli diversi con le seguenti configurazioni, per ciascuno stampare le misure di valutazione sul test set e visualizzare il modello sovrapposto ad esso\n",
    "\n",
    "- **(1a)** regressione lineare semplice\n",
    "- **(1b)** regressione polinomiale di grado 2\n",
    "- **(1c)** regressione polinomiale di grado 3 con standardizzazione delle variabili polinomiali generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sono eseguiti quì tutti gli import necessari da scikit-learn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1a\n",
    "model_a = LinearRegression()\n",
    "model_a.fit(X_train, y_train)\n",
    "print_eval(X_test, y_test, model_a)\n",
    "plot_model_on_data(X_test, y_test, model_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1b\n",
    "model_b = Pipeline([\n",
    "    (\"poly\",   PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    (\"linreg\", LinearRegression())\n",
    "])\n",
    "model_b.fit(X_train, y_train)\n",
    "print_eval(X_test, y_test, model_b)\n",
    "plot_model_on_data(X_test, y_test, model_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1c\n",
    "model_c = Pipeline([\n",
    "    (\"poly\",   PolynomialFeatures(degree=3, include_bias=False)),\n",
    "    (\"scale\",  StandardScaler()),\n",
    "    (\"linreg\", LinearRegression())\n",
    "])\n",
    "model_c.fit(X_train, y_train)\n",
    "print_eval(X_test, y_test, model_c)\n",
    "plot_model_on_data(X_test, y_test, model_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Regolarizzazione e regressione ridge\n",
    "\n",
    "Abbiamo visto come l'addestramento di un modello si compia minimizzando l'errore sui dati di addestramento, dato da\n",
    "\n",
    "$$ E = \\mathrm{media}\\left(\\left(\\mathbf{X}\\mathbf{\\theta}-\\mathbf{y}\\right)^2\\right) $$\n",
    "\n",
    "Per l'esattezza, la formula su cui si basa `LinearRegression` è\n",
    "\n",
    "$$ E = \\left\\Vert\\mathbf{X}\\mathbf{\\theta}-\\mathbf{y}\\right\\Vert_2^2 $$\n",
    "\n",
    "Dove la _norma euclidea_ (o _norma 2_) $\\left\\Vert\\mathbf{x}\\right\\Vert_2$ di un vettore $\\mathbf{x}$ di $n$ elementi è\n",
    "\n",
    "$$ \\left\\Vert\\mathbf{x}\\right\\Vert_2 = \\sqrt{\\sum_{i=1}^n x_i^2} = \\sqrt{x_1^2+\\ldots+x_n^2} $$\n",
    "\n",
    "Tuttavia, questo non garantisce l'accuratezza del modello in generale\n",
    "\n",
    "Soprattutto se il modello ha molti parametri, è possibile che questi vengano \"forzati\" a funzionare bene sui dati d'addestramento, rendendo però il modello poco accurato in generale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Addestriamo ad esempio un modello polinomiale di grado 30 con standardizzazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prm = Pipeline([\n",
    "    (\"poly\",   PolynomialFeatures(degree=30, include_bias=False)),\n",
    "    (\"scale\",  StandardScaler()),\n",
    "    (\"linreg\", LinearRegression())\n",
    "])\n",
    "prm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Valutiamone le misure di accuratezza sia sul training set che sul test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval(X_train, y_train, prm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval(X_test, y_test, prm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La differenza tra le misure suggerisce che il modello sia stato addestrato \"troppo bene\" sul training set ma non sia abbastanza generale (_overfitting_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A dimostrazione, si veda il grafico del modello sovrapposto ai dati del training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_on_data(X_train, y_train, prm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soprattutto nella parte a sinistra, si nota che il modello è stato ottimizzato per minimizzare l'errore anche in casi estremi del training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Vediamo ora il modello sovrapposto al test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_on_data(X_test, y_test, prm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si nota che nei casi estremi del test set, diversi da quelli del training set, l'errore del modello è molto alto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Vediamo quali sono i coefficienti del modello addestrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prm.named_steps[\"linreg\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I coefficienti per i termini di grado più alto sono molto alti in valore assoluto (fino a ${10}^{12}$), questo causa l'andamento irregolare del modello nei casi estremi e i conseguenti errori\n",
    "\n",
    "Come evitare che i coefficienti assumano tali valori?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La **_regolarizzazione_** modifica la funzione d'errore su cui si basa l'addestramento, aggiungendo una penalità per valori estremi dei parametri del modello\n",
    "\n",
    "Nella regolarizzazione _L2_, la più comune, la penalità è proporzionale al quadrato della norma euclidea del vettore $\\mathbf{\\theta}$ dei parametri: in questo modo parametri molto alti in valore assoluto sono molto penalizzati\n",
    "\n",
    "La regressione _ridge_ consiste nella regressione lineare con applicata la regolarizzazione L2, utilizzando quindi la seguente funzione d'errore:\n",
    "\n",
    "$$ E = \\left\\Vert\\mathbf{X}\\mathbf{\\theta}-\\mathbf{y}\\right\\Vert_2^2 + \\alpha\\left\\Vert\\mathbf{\\theta}\\right\\Vert_2^2 $$\n",
    "\n",
    "$\\alpha$ è un iperparametro che controlla il \"peso\" della regolarizzazione: maggiore è $\\alpha$, più i coefficienti saranno forzati ad avere valori piccoli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Per eseguire la regressione ridge usiamo un modello `Ridge` al posto di `LinearRegression`\n",
    "\n",
    "Alla creazione del modello è possibile specificare il peso della regolarizzazione con l'opzione `alpha`\n",
    "\n",
    "Per il resto l'API della classe `Ridge` è identica a quella di `LinearRegression`, possiamo quindi sostituirla nella pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "rrm = Pipeline([\n",
    "    (\"poly\",   PolynomialFeatures(degree=30, include_bias=False)),\n",
    "    (\"scale\",  StandardScaler()),\n",
    "    (\"linreg\", Ridge(alpha=1))  # <-- sostituice LinearRegression()\n",
    "])\n",
    "rrm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Verifichiamo i coefficienti del modello addestrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrm.named_steps[\"linreg\"].coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo che questa volta sono tutti inferiori a 1 in valore assoluto, per effetto della regolarizzazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Con tali, coefficienti, il modello ha un comportamento regolare anche per casi estremi, come si può vedere dal grafico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_on_data(X_test, y_test, rrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Verifichiamo l'accuratezza su training e validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval(X_train, y_train, rrm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval(X_test, y_test, rrm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vediamo che le misure sul training set sono di poco peggiori, ma quelle sul test set sono nettamente migliori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Esercizio 2: Regressione polinomiale al variare di grado e regolarizzazione\n",
    "\n",
    "- **(2a)** Definire una funzione `test_regression` con parametri `degree` e `alpha` che\n",
    "  - definisca un modello di regressione polinomiale di grado `degree` con standardizzazione dei dati e regolarizzazione L2 con peso `alpha`\n",
    "  - _(già implementato)_ addestri tale modello sui dati `X_train`, `y_train`\n",
    "  - _(già implementato)_ restituisca il coefficiente R² del modello calcolato sui dati `X_test`, `y_test`\n",
    "- **(2b)** Generare una lista, array o serie di valori restituiti dalla funzione con `alpha=0.01` e `degree` variabile con valori da 3 a 30\n",
    "- **(2c)** Ripetere il punto 2b con `alpha=10`\n",
    "- **(2d)** Visualizzare i risultati in un grafico a linea (`plt.plot`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2a\n",
    "def test_regression(degree, alpha):\n",
    "    \n",
    "    rrm = Pipeline([\n",
    "    (\"poly\",   PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "    (\"scale\",  StandardScaler()),\n",
    "    (\"linreg\", Ridge(alpha=alpha))\n",
    "    ])\n",
    "    rrm.fit(X_train, y_train)\n",
    "    return rrm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2b\n",
    "degrees = np.arange(3, 31)\n",
    "valuesA = [test_regression(degree, 0.01) for degree in degrees]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2c\n",
    "valuesB = [test_regression(degree, 10) for degree in degrees]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2d\n",
    "plt.plot(range(3, 31), valuesA, \"-ro\")\n",
    "plt.plot(range(3, 31), valuesB, \"-bo\")\n",
    "plt.grid()\n",
    "plt.xlabel(\"Grado regr. polinomiale\")\n",
    "plt.ylabel(\"Score R²\")\n",
    "# aggiungiamo una legenda al grafico\n",
    "plt.legend([\"α = 0.01\", \"α = 10\"], loc=\"lower right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Caso di studio: Predizione dei prezzi delle case\n",
    "\n",
    "Riprendiamo dalla scorsa esercitazione il dataset relativo ai prezzi delle case\n",
    "\n",
    "Forniamo tale dataset all'URL https://git.io/fjGjx già adattato per essere caricato con `read_csv` con le opzioni di default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOUSING_DATA_URL = \"https://github.com/datascienceunibo/dialab2024/raw/main/Regressione_non_Lineare/housing.csv\"\n",
    "\n",
    "import os.path\n",
    "if not os.path.exists(\"housing.csv\"):\n",
    "    from urllib.request import urlretrieve\n",
    "    urlretrieve(HOUSING_DATA_URL, \"housing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv(\"housing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lista delle variabili\n",
    "\n",
    "- CRIM: tasso di criminalità pro capite per zona\n",
    "- ZN: proporzione terreno residenziale per lotti maggiori di 25.000 piedi quadrati (circa 2300 m2)\n",
    "- INDUS: proporzione di acri industriali non commerciali per città\n",
    "- CHAS: variabile fittizia Charles River, 1 se il tratto affianca il fiume, altrimenti 0\n",
    "- NOX: concentrazione di ossido d’azoto (parti per 10 milioni)\n",
    "- RM: numero medio di stanze per abitazione\n",
    "- AGE: proporzione delle unità abitate costruite prima del 1940\n",
    "- DIS: distanze pesate verso i cinque uffici di collocamento di Boston\n",
    "- RAD: indice di accessibilità rispetto alle grandi vie radiali di comunicazione\n",
    "- TAX: tasso di imposte sulla casa per 10.000 dollari\n",
    "- PTRATIO: rapporto allievi-docenti per città\n",
    "- B: 1000(Bk - 0.63)2, dove Bk è la proporzione di persone di origine afroamericana\n",
    "- LSTAT: percentuale di popolazione con basso reddito\n",
    "- **MEDV: valore mediano delle abitazioni di proprietà in migliaia di dollari**\n",
    "  - vogliamo stimare il valore di questa variabile in funzione delle altre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "housing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estraiamo dal frame\n",
    "\n",
    "- la serie `y` con i valori della variabile `MEDV` da prevedere\n",
    "- il frame `X` con i valori di tutte le altre variabili, utilizzabili per la predizione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = housing[\"MEDV\"]\n",
    "X = housing.drop(columns=\"MEDV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Dividiamo i dati caricati casualmente in training e test set con la funzione `train_test_split`\n",
    "\n",
    "- con `test_size` indichiamo quanti dati vanno nel test set, i restanti andranno nel training set\n",
    "- con `random_state` fissiamo un seed per la suddivisione casuale\n",
    "- la funzione mescola i dati di `X` e `y` in modo congiunto, mantenendo la corrispondenza esistente tra le posizioni dei dati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=1/3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Esercizio 3: Valutazione modelli con regolarizzazione/standardizzazione\n",
    "\n",
    "Addestrare sul training set e stampare le metriche di valutazione sul test set di...\n",
    "\n",
    "- **(a)** un modello `model_a` di regressione lineare semplice\n",
    "- **(b)** un modello `model_b` di regressione lineare con regolarizzazione L2 (regressione ridge), assumendo $\\alpha=1$\n",
    "- **(c)** un modello `model_c` di regressione lineare con standardizzazione delle feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3a\n",
    "model_a = LinearRegression()\n",
    "model_a.fit(X_train, y_train)\n",
    "print_eval(X_test, y_test, model_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3b\n",
    "model_b = Ridge(alpha=1)\n",
    "model_b.fit(X_train, y_train)\n",
    "print_eval(X_test, y_test, model_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3c\n",
    "model_c = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"lr\", LinearRegression())\n",
    "])\n",
    "model_c.fit(X_train, y_train)\n",
    "print_eval(X_test, y_test, model_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisi coefficienti dei modelli\n",
    "\n",
    "Visualizziamo ora in un unico frame i coefficienti di tutti e tre i modelli (una riga per variabile, una colonna per modello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    \"linear\": model_a.coef_,\n",
    "    \"ridge\": model_b.coef_,\n",
    "    \"scaled\": model_c.named_steps[\"lr\"].coef_\n",
    "}, index=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In tutti e tre i modelli, dai segni dei coefficienti possiamo vedere quali fenomeni influiscono positivamente e negativamente sul prezzo\n",
    "\n",
    "Ad esempio il prezzo delle case è più alto se vicine al fiume (`CHAS`), mentre decresce con la criminalità (`CRIM`)\n",
    "\n",
    "Nella regressione ridge i valori assoluti più alti sono ridotti (es. `NOX` e `RM`)\n",
    "\n",
    "Con la standardizzazione delle feature otteniamo valori su scale simili, che possiamo confrontare alla pari\n",
    "\n",
    "Ad esempio negli altri modelli il coefficiente di `NOX` è alto in valore assoluto perché i valori di tale variabile sono bassi (la media è circa 0.55, contro quelle superiori a 3 delle altre variabili)\n",
    "\n",
    "Nel modello con standardizzazione appaiono invece più importanti il numero di stanze (`RM`) e la distanza dagli uffici di collocamento (`DIS`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regressione Lasso\n",
    "\n",
    "La regolarizzazione L2 vista sopra impedisce che i parametri del modello assumano valori troppo alti\n",
    "\n",
    "I valori dei parametri sono comunque tutti non nulli, tutte le variabili vengono coinvolte nella predizione\n",
    "\n",
    "Vorremmo addestrare un modello meno complesso, dove alcuni parametri hanno valori nulli, **ignorando completamente le variabili meno rilevanti**, incluse ad es. variabili con valori dipendenti da altre (_multicollinearità_)\n",
    "\n",
    "Questo si può ottenere tramite la regolarizzazione L1, basata sulla norma 1, definita su un vettore $\\mathbf{x}$ di $n$ elementi come\n",
    "\n",
    "$$ \\left\\Vert\\mathbf{x}\\right\\Vert_1 = \\sum_{i=1}^n{\\left\\vert x_i\\right\\vert} = \\left\\vert x_1\\right\\vert+\\ldots+\\left\\vert x_n\\right\\vert $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La regressione _lasso_ consiste nella regressione lineare con regolarizzazione L1, basata quindi sul minimizzare la funzione d'errore\n",
    "\n",
    "$$ E = \\frac{1}{2m}\\left\\Vert\\mathbf{X}\\mathbf{\\theta}-\\mathbf{y}\\right\\Vert_2^2 + \\alpha\\left\\Vert\\mathbf{\\theta}\\right\\Vert_1 $$\n",
    "\n",
    "Come per la regressione ridge, il parametro $\\alpha$ controlla il peso della regolarizzazione\n",
    "\n",
    "La regressione lasso si esegue usando un modello `Lasso`, su cui possiamo impostare come in `Ridge` il parametro `alpha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\", Lasso(alpha=1))\n",
    "])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Vediamo i coefficienti del modello risultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(model.named_steps[\"regr\"].coef_, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La regolarizzazione L1 ha contribuito ad annullare quanti più coefficienti possibile, creando un modello che considera solo 5 variabili\n",
    "\n",
    "Ma qual'è l'accuratezza di tale modello?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'accuratezza è peggiore rispetto ai casi precedenti: in questo caso la regolarizzazione è stata eccessiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cosa succede diminuendo il parametro `alpha`, ovvero il peso della regolarizzazione?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\", Lasso(alpha=0.2)) # <-- cambiato da 1\n",
    "])\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.Series(model.named_steps[\"regr\"].coef_, X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I coefficienti non nulli sono aumentati da 5 a 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print_eval(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'accuratezza è di poco inferiore a quella ottenuta con gli altri modelli\n",
    "\n",
    "Questo modello richiede però solo 9 variabili invece di 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Elastic Net\n",
    "\n",
    "La regressione _elastic net_ combina insieme le regolarizzazioni L2 e L1 usate in ridge e lasso\n",
    "\n",
    "Si applica in scikit-learn tramite la classe `ElasticNet`, per cui l'errore è calcolato come:\n",
    "\n",
    "$$ E = \\underbrace{\\frac{1}{2m} ||X\\theta - y||_2 ^ 2}_{\\text{errore sui dati}} + \\underbrace{\\alpha \\rho ||\\theta||_1}_{\\text{L1}} + \\underbrace{\\frac{\\alpha(1-\\rho)}{2} ||\\theta||_2 ^ 2}_{\\text{L2}} $$\n",
    "\n",
    "I parametri impostabili sono\n",
    "\n",
    "- `alpha` ($\\alpha$) che determina il peso generale della regolarizzazione\n",
    "- `l1_ratio` ($\\rho$, compreso tra 0 e 1) che determina il peso di L1 relativo al totale (con $\\rho=1$ si ha la regressione lasso, con $\\rho=0$ la ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "model = Pipeline([\n",
    "    (\"scale\",  StandardScaler()),\n",
    "    (\"regr\", ElasticNet(alpha=0.2, l1_ratio=0.1))\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "print_eval(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Esercizio 4: Elastic Net con pesi separati\n",
    "\n",
    "- **(4a)** Definire una funzione `elastic_net_with_alphas` che restituisca un modello `ElasticNet` (non addestrato) con pesi dati separatamente per la regolarizzazione L2 e L1\n",
    "  - si ricordi che il parametro `alpha` è la somma dei due pesi\n",
    "- **(4b)** Servendosi di tale funzione, addestrare e validare un modello elastic net con $\\alpha_{L2}=1, \\alpha_{L1}=0.1$ e standardizzazione delle feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4a\n",
    "def elastic_net_with_alphas(alpha_l2, alpha_l1):\n",
    "    alpha = alpha_l1 + alpha_l2\n",
    "    l1_ratio = alpha_l1 / alpha\n",
    "    return ElasticNet(alpha=alpha, l1_ratio=l1_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4b\n",
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  elastic_net_with_alphas(1, 0.1))\n",
    "])\n",
    "model.fit(X_train, y_train)\n",
    "print_eval(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressione polinomiale multivariata\n",
    "\n",
    "Abbiamo visto in precedenza la regressione polinomiale su una sola variabile $X$ (univariata), corrispondente alla regressione lineare sulle variabili $X,X^2,X^3,\\ldots$\n",
    "\n",
    "Per generare queste variabili utilizziamo il filtro `PolynomialFeatures`\n",
    "\n",
    "Siano date ad esempio due osservazioni di una variabile..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.array([ [ 2],\n",
    "                    [-3] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo ottenere ad es. le potenze fino al 4° grado (`include_bias=True` specifica di non includere il termine di grado 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=4, include_bias=False)\n",
    "poly.fit_transform(sample)\n",
    "#         X   X^2   X^3   X^4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In presenza di più di una variabile, la regressione polinomiale genera tutti i possibili termini fino al grado impostato, includendo anche **termini basati su più variabili**\n",
    "\n",
    "Vediamo un esempio con 2 generiche variabili $A$ e $B$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                     A   B\n",
    "sample = np.array([ [ 2, -3],\n",
    "                    [ 4, -5] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applicando il filtro `PolynomialFeatures` con grado 2..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly.fit_transform(sample)\n",
    "#         A     B    A^2   A*B   B^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le variabili generate sono 5: $A,B,A^2,AB,B^2$\n",
    "\n",
    "Oltre ai quadrati delle singole variabili abbiamo quindi anche i prodotti tra di esse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Possiamo usare il metodo `get_feature_names_out` del filtro per avere un array delle variabili calcolate _(`get_feature_names` in versioni più vecchie di scikit-learn)_\n",
    "\n",
    "- il filtro deve già essere stato \"addestrato\" con `fit` o `fit_transform`\n",
    "- è possibile passare una lista di nomi delle variabili originali, altrimenti sono usati `x0`, `x1`, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.get_feature_names_out([\"A\", \"B\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Aumentando il grado massimo, le variabili generate **aumentano rapidamente**\n",
    "\n",
    "Ad esempio, aumentando il grado da 2 a 3..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "poly.fit_transform(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...generiamo 9 variabili, ovvero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.get_feature_names_out([\"A\", \"B\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cosa succede con un numero iniziale di variabili più alto?\n",
    "\n",
    "Selezioniamo ad esempio dalle variabili X del dataset `housing` le 5 feature che avevano coefficiente non nullo nella prima regressione Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la lista delle feature da considerare è:\n",
    "Xsub_feats = [\"CHAS\", \"RM\", \"PTRATIO\", \"B\", \"LSTAT\"]\n",
    "# creo una selezione sia dal training che dal validation set\n",
    "Xsub_train = X_train[Xsub_feats]\n",
    "Xsub_test = X_test[Xsub_feats]\n",
    "# stampo il numero di colonne\n",
    "Xsub_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generando le feature polinomiali con grado massimo 2..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly.fit_transform(Xsub_train).shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...otteniamo 20 feature distinte!\n",
    "\n",
    "Le feature includono infatti tutte le possibili coppie di variabili, oltre ai quadrati di ciascuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly.get_feature_names_out(Xsub_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "È possibile in alternativa generare solamente le feature derivate dalla moltiplicazione (\"interazione\") di variabili diverse (escludendo quindi i quadrati) impostando `interaction_only=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "poly.fit_transform(Xsub_train).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "poly.get_feature_names_out(Xsub_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Aumentando ulteriormente il grado, il numero di variabili cresce esponenzialmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "poly.fit_transform(Xsub_train).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=4, include_bias=False)\n",
    "poly.fit_transform(Xsub_train).shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usiamo un ciclo for per testare rapidamente valori successivi\n",
    "for degree in range(3, 9):\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    feats_count = poly.fit_transform(Xsub_train).shape[1]\n",
    "    print(f\"{degree}° grado: {feats_count} variabili\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Questa crescita è ancora più evidente con la matrice completa `X_train`, con 13 variabili"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generando le feature polinomiali con grado massimo 2 otteniamo 104 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly.fit_transform(X_train).shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Aumentando ulteriormente il grado, il numero di variabili cresce enormemente (con grado 10 si supera il milione di variabili!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for degree in range(3, 8):\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    feats_count = poly.fit_transform(X_train).shape[1]\n",
    "    print(f\"{degree}° grado: {feats_count} variabili\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "All'aumentare delle variabili, aumenta il tempo necessario per l'addestramento del modello\n",
    "\n",
    "Prendiamo ad esempio come riferimento un modello ElasticNet polinomiale con standardizzazione delle feature generate\n",
    "\n",
    "Creiamo una funzione che crea tale modello con la possibilità di impostare il grado delle feature generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_std_elasticnet(degree):\n",
    "    return Pipeline([\n",
    "        (\"poly\", PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "        (\"std\",  StandardScaler()),\n",
    "        (\"regr\", ElasticNet(alpha=0.5, l1_ratio=0.2))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Eseguiamo la prova su un modello di grado 2 per predire il prezzo delle case col sottoinsieme di 5 feature indicato sopra\n",
    "\n",
    "Usiamo il comando \"magico\" `%time` per riportare in output il tempo di esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = poly_std_elasticnet(2)\n",
    "%time model.fit(Xsub_train, y_train)\n",
    "print_eval(Xsub_test, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esercizio 5: Regressione polinomiale con molte variabili\n",
    "\n",
    "Usando la funzione `poly_std_elasticnet` definita sopra per configurare i modelli, addestrare sul training set misurando il tempo necessario con `%time` e valutare l'accuratezza sul test set di:\n",
    "\n",
    "- **(5a)** un modello di grado 2 su tutte le feature\n",
    "- **(5b)** un modello di grado 5 sul sottoinsieme di 5 feature\n",
    "- **(5c)** un modello di grado 5 su tutte le feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5a\n",
    "model = poly_std_elasticnet(2)\n",
    "%time model.fit(X_train, y_train)\n",
    "print_eval(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5b\n",
    "model = poly_std_elasticnet(5)\n",
    "%time model.fit(Xsub_train, y_train)\n",
    "print_eval(Xsub_test, y_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5c\n",
    "model = poly_std_elasticnet(5)\n",
    "%time model.fit(X_train, y_train)\n",
    "print_eval(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dagli esercizi emerge che l'accuratezza del modello migliora sensibilmente, ma **con tempi di addestramento molto superiori**\n",
    "\n",
    "- più di 10 volte superiori con 5 feature\n",
    "- più di 100 volte superiori con 13 feature\n",
    "\n",
    "Con dataset più grandi, avremmo tempi di addestramento insostenibili"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Regressione con funzioni kernel\n",
    "\n",
    "Nella regressione polinomiale si eseguono prodotti tra dati con dimensioni aggiunte e rappresentate esplicitamente\n",
    "\n",
    "Le _funzioni kernel_ permettono di calcolare gli stessi prodotti senza calcolare esplicitamente le dimensioni aggiunte\n",
    "\n",
    "Questo permette di ottenere **modelli non lineari senza l'aggiunta di variabili**\n",
    "\n",
    "Esistono diverse funzioni kernel utilizzabili con diversi parametri impostabili\n",
    "\n",
    "Ad esempio, il kernel polinomiale è definito dalla formula\n",
    "\n",
    "$$ K(\\mathbf{a},\\mathbf{b}) = \\left(\\mathbf{a}\\cdot\\mathbf{b}+c\\right)^d $$\n",
    "\n",
    "$d$ e $c$ sono parametri del kernel, in particolare $d$ è il grado del polinomio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "La classe `KernelRidge` implementa la regressione ridge con l'applicazione di una funzione kernel\n",
    "\n",
    "Col parametro `kernel` si indica il tipo di kernel con una stringa, ad es. `\"poly\"` per un kernel polinomiale\n",
    "\n",
    "Ulteriori parametri riguardano il kernel, per quello polinomiale sono `degree` ($d$) e `coef0` ($c$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=20, kernel=\"poly\", degree=5))\n",
    "])\n",
    "%time model.fit(X_train, y_train)\n",
    "print_eval(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo ottenuto un'accuratezza più elevata rispetto ai modelli lineari, ma in tempi molto più brevi rispetto alla regressione polinomiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Aumentando arbitrariamente il grado del polinomio, il tempo impiegato per l'addestramento non cambia (in questo caso comunque un grado alto non porta ad un modello accurato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=20, kernel=\"poly\", degree=15))\n",
    "])\n",
    "%time model.fit(X_train, y_train)\n",
    "print_eval(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Va però ricordato che la complessità cresce quadraticamente col numero di istanze di training\n",
    "\n",
    "Ad esempio, addestrando un modello su _tutti_ i dati invece che sul solo training set, quindi sul 50\\% di istanze in più..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=20, kernel=\"poly\", degree=5))\n",
    "])\n",
    "%time model.fit(X, y)\n",
    "print_eval(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... il tempo necessario è circa il doppio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Possiamo testare anche funzioni kernel diverse, ad esempio RBF (_radial basis function_)\n",
    "\n",
    "RBF ha valori tanto più elevati quanto più i valori X sono vicini a 0 (ovvero la media, usando dati standardizzati)\n",
    "\n",
    "La funzione RBF ha la forma di una gaussiana, di cui si può impostare l'ampiezza col parametro `gamma`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=20, kernel=\"rbf\", gamma=0.01))\n",
    "])\n",
    "%time model.fit(X_train, y_train)\n",
    "print_eval(X_test, y_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In questo caso specifico il kernel RBF non funziona bene tanto quanto il polinomiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## k-Fold Cross Validation\n",
    "\n",
    "La _cross validation_ si riferisce in generale alla valutazione di un modello di predizione su dati differenti rispetto a quelli su cui è addestrato\n",
    "\n",
    "La cross validation prevede in generale di generare diverse suddivisioni dei dati in _training set_ e _validation set_ e per ciascuna addestrare un modello sul primo e misurare le metriche di accuratezza sul secondo\n",
    "\n",
    "Finora abbiamo usato il semplice metodo _hold-out_, dove viene effettuata una singola suddivisione dei dati con proporzioni configurabili\n",
    "\n",
    "_k-fold_ è un metodo comune per eseguire una valutazione più accurata del modello\n",
    "\n",
    "- i dati sono divisi causalmente in k gruppi (_fold_)\n",
    "- ciascun gruppo è usato come test set di un modello addestrato su tutti gli altri gruppi\n",
    "- i risultati dei singoli test sono aggregati\n",
    "\n",
    "scikit-learn fornisce un supporto generico per la cross-validation di modelli tramite diversi metodi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per prima cosa va creato un oggetto che definisce il metodo di cross-validation da applicare\n",
    "\n",
    "Usiamo ad esempio un oggetto della classe `KFold`\n",
    "\n",
    "- il primo parametro è il numero di fold (k) da usare\n",
    "- specifichiamo inoltre che i dati sono distribuiti casualmente e il seed da usare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold_5 = KFold(5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gli oggetti di questo tipo forniscono un metodo `split`, che dato un dataset genera le suddivisioni training/test secondo la configurazione data\n",
    "\n",
    "Per ogni suddivisione sono dati un array di etichette delle righe da includere nel training set (`train_index`) e l'array complementare di etichette delle righe da includere nel validation set (`val_index`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (train_index, val_index) in enumerate(kfold_5.split(X, y), start=1):\n",
    "    print(f\"Fold {i}: {len(train_index)} istanze di training, {len(val_index)} istanze di validazione\")\n",
    "    # per ottenere ad es. X_train: X[train_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo la configurazione di un modello da validare, ad es. il modello kernel ridge visto sopra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=20, kernel=\"poly\", degree=5))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Per eseguire la CV usiamo quindi la funzione `cross_validate`, a cui passiamo in input:\n",
    "\n",
    "- la definizione di un modello, di cui viene addestrata una copia con la stessa configurazione per ciascun fold\n",
    "- i dati, divisi come per `fit` in valori di variabili indipendenti (X) e dipendente (y)\n",
    "- un oggetto `cv` che definisce il metodo di cross validation, in questo caso l'istanza di `KFold`\n",
    "- l'opzione `return_train_score=True` per eseguire la valutazione anche sui training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "cv_result = cross_validate(model, X, y, cv=kfold_5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Otteniamo un dizionario con un vettore per ciascuna misura estratta, ciascuno ha un valore per ogni fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Per maggiore comodità raccogliamo i dati in un DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_table = pd.DataFrame(cv_result)\n",
    "cv_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per ognuno dei 5 fold vediamo riportati\n",
    "\n",
    "- i secondi impiegati per l'addestramento (`fit_time`) e la validazione (`score_time`) del modello\n",
    "- il punteggio calcolato su training set (`train_score`) e validation set (`test_score`)\n",
    "\n",
    "Il punteggio è quello calcolato dal metodo `score` del modello, ovvero il coefficiente R²"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Per avere un dato generale sulla bontà del modello, possiamo calcolare media e deviazione standard dei punteggi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_table[[\"train_score\", \"test_score\"]].agg([\"mean\", \"std\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tale valutazione è più affidabile di quella col metodo hold-out, ottenuta da un singolo modello\n",
    "\n",
    "Ci permette inoltre di valutare la \"robustezza\" del modello, ovvero quanto l'accuratezza sia stabile addestrandosi su set di dati diversi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Esercizio 6: Cross-validation su modello kernel ridge\n",
    "\n",
    "- **(6a)** Definire un modello di regressione kernel ridge su feature standardizzate con kernel polinomiale di 3° grado e $\\alpha=10$\n",
    "- **(6b)** Eseguire la cross-validation del modello, utilizzando 5 fold dell'intero dataset `housing` (`X` e `y`) generati dall'oggetto `kfold_5` definito sopra\n",
    "- **(6c)** Calcolare la media e la deviazione standard dei punteggi R² ottenuti dalla validazione di ciascun fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6a\n",
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  KernelRidge(alpha=10, kernel=\"poly\", degree=3))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6b\n",
    "cv_results = cross_validate(model, X, y, cv=kfold_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6c\n",
    "cv_scores = cv_results[\"test_score\"]\n",
    "cv_scores.mean(), cv_scores.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Ricerca degli iperparametri con grid search\n",
    "\n",
    "Sui modelli utilizzati finora abbiamo impostato manualmente i valori di diversi iperparametri: grado della regressione polinomiale, peso della regolarizzazione, ...\n",
    "\n",
    "L'accuratezza del modello può dipendere fortemente da questi valori\n",
    "\n",
    "Scelto un generico modello da utilizzare (es. regressione polinomiale o kernel ridge), vorremmo **individuare i valori degli iperparametri che ne massimizzino l'accuratezza**\n",
    "\n",
    "scikit-learn fornisce un supporto per eseguire automaticamente la cross validation di un modello con diversi valori degli iperparametri tramite la _grid search_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Consideriamo ad esempio un modello _elastic net_ di cui fissiamo arbitrariamente l'iperparametro `l1_ratio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ElasticNet(l1_ratio=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vorremmo trovare il migliore valore possibile dell'iperparametro `alpha` tra un insieme di valori possibili, ovvero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_alphas = [0.1, 1, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo una _griglia_ degli iperparametri, ovvero un dizionario in cui associamo ai nomi degli iperparametri variabili i valori che possono assumere\n",
    "\n",
    "In questo caso abbiamo un unico parametro variabile, `alpha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\"alpha\": candidate_alphas}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Definiamo ora un modello `GridSearchCV` indicando\n",
    "\n",
    "- il modello \"base\" con i parametri fissati a priori\n",
    "- la griglia dei parametri variabili\n",
    "- un metodo `cv` di cross validation da usare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(model, grid, cv=kfold_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come per i modelli base, usiamo il metodo `fit` per eseguire l'addestramento, passando la matrice X e il vettore y\n",
    "\n",
    "Per ogni valore possibile di `alpha`, scikit-learn esegue la cross-validation per calcolare il punteggio R² medio del modello con quel valore di `alpha`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In seguito ai test, il modello impostato viene (di default) riaddestrato su tutti i dati forniti, usando gli iperparametri che han dato il miglior punteggio medio\n",
    "\n",
    "Il modello finale è accessibile all'attributo `gs_best_estimator_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dall'attributo `best_params_` possiamo vedere quali sono i valori selezionati dalla griglia degli iperparametri per tale modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "L'oggetto `GridSearchCV` addestrato può essere usato come un normale modello di predizione, le chiamate a `predict` e altri metodi sono girate al `best_estimator_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prezzo predetto per la prima riga del dataset\n",
    "gs.predict(X.iloc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalente a\n",
    "gs.best_estimator_.predict(X.iloc[[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possiamo infine valutare il modello sul test set, non utilizzato nella grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_eval(X_test, y_test, gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "L'attributo `cv_results_` fornisce risultati dettagliati su tutti gli iperparametri testati\n",
    "\n",
    "Come per `cross_validate`, raccogliamo i risultati in un `DataFrame` per visualizzarli meglio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gs.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dati riportati per ciascun test includono:\n",
    "- `{mean|std}_{fit|score}_time`: media/dev. standard dei tempi di addestramento/valutazione sui diversi fold\n",
    "- `param_X`: valore del parametro X\n",
    "- `params`: dizionario col valore di tutti i parametri\n",
    "- `splitN_test_score`: punteggio della valutazione sull'N-esimo fold\n",
    "- `{mean|std}_test_score`: media/dev. standard dei punteggi sui diversi fold\n",
    "- `rank_test_score`: ranking del punteggio, 1 è il migliore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cosa succede con due iperparametri variabili?\n",
    "\n",
    "Oltre a 3 valori possibili per `alpha`, impostiamo 3 valori possibili anche per `l1_ratio`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ElasticNet()\n",
    "grid = {\n",
    "    \"alpha\":    [0.1, 1, 10],\n",
    "    \"l1_ratio\": [0.1, 0.2, 0.3]\n",
    "}\n",
    "gs = GridSearchCV(model, grid, cv=kfold_5)\n",
    "gs.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizzo i risultati ordinati per punteggio R² medio decrescente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(gs.cv_results_).sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn ha generato e testato **tutte le combinazioni possibili** dei valori degli iperparametri, in tutto 3×3 = 9 configurazioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Grid search su pipeline\n",
    "\n",
    "Possiamo usare `GridSearchCV` anche con una pipeline testando diversi valori per gli iperparametri di tutti i componenti, sia modello che filtri\n",
    "\n",
    "Consideriamo ad esempio il seguente modello polinomiale con regolarizzazione L2, su cui sono variabili\n",
    "\n",
    "- il grado del polinomio (attributo `degree` del filtro `poly`)\n",
    "- il peso della regolarizzazione (attributo `alpha` del modello `regr`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"poly\",  PolynomialFeatures(include_bias=False)),\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\",  Ridge())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per riferirsi ai parametri dei singoli componenti, usiamo la notazione `componente__parametro` _(con DUE underscore in mezzo)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {\n",
    "    # grado polinomio (parametro \"degree\" del filtro \"poly\")\n",
    "    \"poly__degree\": [2, 3],\n",
    "    # peso regolarizzazione (parametro \"alpha\" del modello \"regr\")\n",
    "    \"regr__alpha\":  [0.1, 1, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il resto del procedimento rimane invariato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(model, grid, cv=kfold_5)\n",
    "gs.fit(X_train, y_train);\n",
    "pd.DataFrame(gs.cv_results_).sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Nella pipeline possiamo impostare un intero componente come parametro variabile, con la possibilità di rimuoverlo impostandolo a `None`\n",
    "\n",
    "Possiamo ad esempio testare un modello con e senza standardizzazione delle feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    (\"scale\", None),   # uso None come segnaposto\n",
    "    (\"regr\",  Ridge())\n",
    "])\n",
    "grid = {\n",
    "    # scale = standardizzazione oppure nulla\n",
    "    \"scale\": [None, StandardScaler()],\n",
    "    \"regr__alpha\": [0.1, 1, 10]\n",
    "}\n",
    "gs = GridSearchCV(model, grid, cv=kfold_5)\n",
    "gs.fit(X_train, y_train);\n",
    "pd.DataFrame(gs.cv_results_).sort_values(\"mean_test_score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Esercizio 7: Grid search\n",
    "\n",
    "Per ciascuno dei modelli indicati sotto eseguire una grid search con cross-validation a 5 fold sul training set, stampare gli iperparametri migliori selezionati dalla grid search e stampare le misure di accuratezza del modello migliore sul test set\n",
    "\n",
    "- **(7a)** modello di regressione elastic net polinomiale con\n",
    "  - grado 2 o 3\n",
    "  - standardizzazione delle feature generate\n",
    "  - `alpha` pari a 0.1, 1 o 10\n",
    "  - `l1_ratio` pari a 0.1, 0.25 o 0.5\n",
    "- **(7b)** modello kernel ridge con\n",
    "  - standardizzazione dei dati\n",
    "  - kernel polinomiale di grado compreso tra 2 e 6\n",
    "  - `alpha` (regolarizzazione) pari a 0.01, 0.1, 1 o 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.980e+02, tolerance: 2.466e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.215e+01, tolerance: 2.256e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.381e+01, tolerance: 2.407e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.990e+02, tolerance: 2.289e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.213e+02, tolerance: 2.474e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.222e+01, tolerance: 2.466e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.287e+01, tolerance: 2.256e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.065e+00, tolerance: 2.407e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.809e+01, tolerance: 2.289e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.717e+01, tolerance: 2.474e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.122e+00, tolerance: 2.466e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.298e+00, tolerance: 2.474e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.088e+03, tolerance: 2.466e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.604e+02, tolerance: 2.256e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.745e+02, tolerance: 2.407e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.905e+02, tolerance: 2.289e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.051e+03, tolerance: 2.474e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.071e+02, tolerance: 2.466e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.852e+02, tolerance: 2.256e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.216e+02, tolerance: 2.407e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.648e+02, tolerance: 2.289e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.853e+02, tolerance: 2.474e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.278e+02, tolerance: 2.466e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.907e+01, tolerance: 2.256e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.099e+02, tolerance: 2.407e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.571e+02, tolerance: 2.289e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.849e+02, tolerance: 2.474e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'poly__degree': 2, 'regr__alpha': 0.1, 'regr__l1_ratio': 0.1}\n",
      "   Mean squared error: 15.041\n",
      "       Relative error: 13.87150%\n",
      "R-squared coefficient: 0.80004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.787e+02, tolerance: 2.977e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "#7a\n",
    "model = Pipeline([\n",
    "    (\"poly\", PolynomialFeatures(include_bias=False)),\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\", ElasticNet())\n",
    "])\n",
    "grid = {\n",
    "    \"poly__degree\": [2, 3],\n",
    "    \"regr__alpha\": [0.1, 1, 10],\n",
    "    \"regr__l1_ratio\": [0.1, 0.25, 0.5]\n",
    "}\n",
    "gs = GridSearchCV(model, grid, cv=kfold_5)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_params_)\n",
    "print_eval(X_test, y_test, gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'regr__alpha': 1, 'regr__degree': 2}\n",
      "   Mean squared error: 11.303\n",
      "       Relative error: 12.20756%\n",
      "R-squared coefficient: 0.84973\n"
     ]
    }
   ],
   "source": [
    "#7b\n",
    "model = Pipeline([\n",
    "    (\"scale\", StandardScaler()),\n",
    "    (\"regr\", KernelRidge(kernel=\"poly\"))\n",
    "])\n",
    "grid = {\n",
    "    \"regr__degree\": range(2, 7),\n",
    "    \"regr__alpha\": [0.01, 0.1, 1, 10],\n",
    "}\n",
    "gs = GridSearchCV(model, grid, cv=kfold_5)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_params_)\n",
    "print_eval(X_test, y_test, gs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Nested cross-validation\n",
    "\n",
    "Sopra abbiamo validato il risultato finale della grid search su un test set separato\n",
    "\n",
    "La _nested cross-validation_ prevede che siano generati **k fold \"esterni\"** su tutti i dati disponibili e che **per ciascuno** si esegua il tuning degli iperparametri con una cross validation \"interna\" usando le parti di training dei fold esterni\n",
    "\n",
    "I criteri con cui si eseguono le cross validation esterna ed interna possono differire, es. diverso numero di fold\n",
    "\n",
    "Ipotizziamo ad esempio di usare 3 fold esterni e 5 interni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "outer_cv = KFold(3, shuffle=True, random_state=42)\n",
    "inner_cv = KFold(5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Esercizio 8 (avanzato): Nested cross validation\n",
    "\n",
    "Completare l'implementazione una funzione `nested_cv` che esegua la nested cross validation di un modello `model` con griglia di parametri variabili `grid`\n",
    "\n",
    "- _(già implementato)_ predisporre una lista vuota in cui salvare i punteggi ottenuti su ogni fold esterno\n",
    "- _(già implementato)_ usare un ciclo `for` per iterare tutti i fold esterni (T, V) del dataset `X`, `y`\n",
    "  - il metodo `split` di `outer_cv` fornisce per ogni fold gli indici delle istanze di training e di validation\n",
    "- su ciascun fold esterno, eseguire la grid search con modello e parametri dati in ingresso alla funzione sui dati T, applicando `inner_cv` come cross validation\n",
    "- per ogni modello generato, salvare nella lista di punteggi il R² ottenuto dalla validazione sui dati V\n",
    "- _(già implementato)_ restituire la lista alla fine del ciclo\n",
    "\n",
    "Testare la funzione su uno dei modelli usati sopra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_cv(model, grid):\n",
    "    results = []\n",
    "    for train_indices, val_indices in outer_cv.split(X, y):\n",
    "        X_train, y_train = X.iloc[train_indices], y.iloc[train_indices]\n",
    "        X_val, y_val = X.iloc[val_indices], y.iloc[val_indices]\n",
    "        ...\n",
    "    return results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
